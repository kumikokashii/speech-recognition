{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from kaggle_speech_recog import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature and label matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPPED train/audio/_background_noise_/README.md File format b'# Ba'... not understood.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/librosa/filters.py:261: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    }
   ],
   "source": [
    "X_vector_len = 16000\n",
    "train = SpeechList.get_train('train/audio')\n",
    "XY_train_valid = train.get_group_unknown_spectrogram_X_and_Y(X_vector_len=X_vector_len, spec_v='3', take_log=False, \n",
    "                                                             split_noise=True, n_fabricate_noise=1600, \n",
    "                                                             split=0.85)\n",
    "\n",
    "# XY_train_valid = (X_train_known, X_train_unknown, Y_train_known, Y_train_unknown, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get logits from trained neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2log = 'logs/Ensemble_graph_04_9models_run_01.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_03_lr_decay_run_01_group_unknown/best/model-57354\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/NoveltyDetectionSpectrogramMultiLSTMRandomInputModify_graph_01_run_01/best/model-82750\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_02_run_01/best/model-90650\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify2_graph_02_lower_lr_lr_decay_run_01_group_unknown/best/model-53088\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramCLSTMBidirectional_graph_03_run_01/best/model-17450\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramDSConvDropout_graph_01_run_01/best/model-22740\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM2_graph_01_run_01_group_unknown/best/model-23858\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_03_conv3x3_lower_lr_run_01_group_unknown/best/model-142358\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_04_conv5x1_lower_lr_run_01_group_unknown/best/model-229416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_03_lr_decay_run_01_group_unknown/best/model-57354\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/NoveltyDetectionSpectrogramMultiLSTMRandomInputModify_graph_01_run_01/best/model-82750\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_02_run_01/best/model-90650\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify2_graph_02_lower_lr_lr_decay_run_01_group_unknown/best/model-53088\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramCLSTMBidirectional_graph_03_run_01/best/model-17450\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramDSConvDropout_graph_01_run_01/best/model-22740\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM2_graph_01_run_01_group_unknown/best/model-23858\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_03_conv3x3_lower_lr_run_01_group_unknown/best/model-142358\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_04_conv5x1_lower_lr_run_01_group_unknown/best/model-229416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_03_lr_decay_run_01_group_unknown/best/model-57354\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/NoveltyDetectionSpectrogramMultiLSTMRandomInputModify_graph_01_run_01/best/model-82750\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_02_run_01/best/model-90650\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify2_graph_02_lower_lr_lr_decay_run_01_group_unknown/best/model-53088\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramCLSTMBidirectional_graph_03_run_01/best/model-17450\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramDSConvDropout_graph_01_run_01/best/model-22740\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM2_graph_01_run_01_group_unknown/best/model-23858\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_03_conv3x3_lower_lr_run_01_group_unknown/best/model-142358\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_04_conv5x1_lower_lr_run_01_group_unknown/best/model-229416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/Ensemble_graph_04_9models_run_01/best/model-110679\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/Ensemble_graph_04_9models_run_01/best/model-110679\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/Ensemble_graph_04_9models_run_01/best/model-110679\n"
     ]
    }
   ],
   "source": [
    "X_train_known, X_train_unknown, Y_train_known, Y_train_unknown, X_valid, Y_valid = XY_train_valid\n",
    "log = pickle.load(open(path2log, 'rb'))\n",
    "\n",
    "if hasattr(log.t_cnfg, 'ensemble_logs'):\n",
    "    L_train_known = gather_logits(X_train_known, log_dir='logs', logs=log.t_cnfg.ensemble_logs)\n",
    "    L_train_unknown = gather_logits(X_train_unknown, log_dir='logs', logs=log.t_cnfg.ensemble_logs)\n",
    "    L_valid = gather_logits(X_valid, log_dir='logs', logs=log.t_cnfg.ensemble_logs)\n",
    "    \n",
    "GraphClass = globals()[log.graph_name]  # Pick up graph class used to train model\n",
    "graph = GraphClass(log.g_cnfg)  # Load the same graph configuration\n",
    "\n",
    "if hasattr(log.t_cnfg, 'ensemble_logs'):\n",
    "    X2_train_known = graph.get_logits(L_train_known, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)  # Use best model in checkpoint directory\n",
    "    X2_train_unknown = graph.get_logits(L_train_unknown, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "    X2_valid = graph.get_logits(L_valid, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "else:\n",
    "    X2_train_known = graph.get_logits(X_train_known, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "    X2_train_unknown = graph.get_logits(X_train_unknown, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "    X2_valid = graph.get_logits(X_valid, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train IsolationForest and OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = np.concatenate((X2_train_known, X2_train_unknown, X2_valid), axis=0)\n",
    "Y = np.concatenate((Y_train_known, Y_train_unknown, Y_valid), axis=0)\n",
    "Y_argmax = np.argmax(Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict_iso_forest = {}\n",
    "model_dict_one_class_svm = {}\n",
    "\n",
    "iso_forest_contamination = 0.005\n",
    "one_class_svm_nu = 0.01\n",
    "\n",
    "for i in list(set(Y_argmax)):  # [0: # of labels]\n",
    "    i_X2 = X2[np.where(Y_argmax == i)[0], :]\n",
    "    \n",
    "    model_dict_iso_forest[i] = IsolationForest(max_samples=len(i_X2), contamination=iso_forest_contamination).fit(i_X2)\n",
    "    model_dict_one_class_svm[i] = OneClassSVM(nu=one_class_svm_nu).fit(i_X2)\n",
    "\n",
    "# Save for later\n",
    "pickle.dump(model_dict_iso_forest, open('_'.join(['IsolationForests', log.joined_name]), 'wb'))\n",
    "pickle.dump(model_dict_one_class_svm, open('_'.join(['OneClassSVMs', log.joined_name]), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_pick_unknown = True\n",
    "\n",
    "if random_pick_unknown:\n",
    "    i_train_unknown = np.random.choice(len(X2_train_unknown), size=int(len(X2_train_known) / 11), replace=False)\n",
    "    random_X2_train_unknown = X2_train_unknown[i_train_unknown, :]\n",
    "    random_Y_train_unknown = Y_train_unknown[i_train_unknown, :]\n",
    "\n",
    "    X2_train = np.concatenate((X2_train_known, random_X2_train_unknown))\n",
    "    Y_train = np.concatenate((Y_train_known, random_Y_train_unknown))\n",
    "else:\n",
    "    X2_train = np.concatenate((X2_train_known, X2_train_unknown))\n",
    "    Y_train = np.concatenate((Y_train_known, Y_train_unknown))\n",
    "    \n",
    "Y_train_argmax = np.argmax(Y_train, axis=1)\n",
    "Y_valid_argmax = np.argmax(Y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.19578\tvalid-mlogloss:2.19744\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:1.03945\tvalid-mlogloss:1.04728\n",
      "[20]\ttrain-mlogloss:0.601851\tvalid-mlogloss:0.612506\n",
      "[30]\ttrain-mlogloss:0.367786\tvalid-mlogloss:0.380278\n",
      "[40]\ttrain-mlogloss:0.232056\tvalid-mlogloss:0.245855\n",
      "[50]\ttrain-mlogloss:0.151076\tvalid-mlogloss:0.16586\n",
      "[60]\ttrain-mlogloss:0.101926\tvalid-mlogloss:0.117492\n",
      "[70]\ttrain-mlogloss:0.071655\tvalid-mlogloss:0.087732\n",
      "[80]\ttrain-mlogloss:0.052896\tvalid-mlogloss:0.06953\n",
      "[90]\ttrain-mlogloss:0.040938\tvalid-mlogloss:0.057928\n",
      "[100]\ttrain-mlogloss:0.033202\tvalid-mlogloss:0.050776\n",
      "[110]\ttrain-mlogloss:0.027981\tvalid-mlogloss:0.045923\n",
      "[120]\ttrain-mlogloss:0.024376\tvalid-mlogloss:0.042776\n",
      "[130]\ttrain-mlogloss:0.021823\tvalid-mlogloss:0.04053\n",
      "[140]\ttrain-mlogloss:0.019993\tvalid-mlogloss:0.038993\n",
      "[150]\ttrain-mlogloss:0.018593\tvalid-mlogloss:0.038146\n",
      "[160]\ttrain-mlogloss:0.01749\tvalid-mlogloss:0.037388\n",
      "[170]\ttrain-mlogloss:0.016601\tvalid-mlogloss:0.037102\n",
      "[180]\ttrain-mlogloss:0.015888\tvalid-mlogloss:0.036868\n",
      "[190]\ttrain-mlogloss:0.015256\tvalid-mlogloss:0.036512\n",
      "[200]\ttrain-mlogloss:0.01474\tvalid-mlogloss:0.036413\n",
      "[210]\ttrain-mlogloss:0.014268\tvalid-mlogloss:0.03651\n",
      "[220]\ttrain-mlogloss:0.013842\tvalid-mlogloss:0.036555\n",
      "[230]\ttrain-mlogloss:0.013478\tvalid-mlogloss:0.036665\n",
      "[240]\ttrain-mlogloss:0.013136\tvalid-mlogloss:0.036809\n",
      "Stopping. Best iteration:\n",
      "[196]\ttrain-mlogloss:0.014945\tvalid-mlogloss:0.036401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_train = xgb.DMatrix(X2_train, label=Y_train_argmax)\n",
    "xgb_valid = xgb.DMatrix(X2_valid, label=Y_valid_argmax)\n",
    "\n",
    "params = {'objective': 'multi:softprob',  # labels are 1-dim, not one-hot encoded\n",
    "          'num_class': Y_train.shape[-1],\n",
    "          'eval_metric': 'mlogloss', \n",
    "          'eta': 0.05,\n",
    "          'subsample': 0.5,\n",
    "          'max_depth': 1}\n",
    "watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "\n",
    "xgboost = xgb.train(params, xgb_train, num_boost_round=1000, evals=watchlist, \n",
    "                    early_stopping_rounds=50, verbose_eval=10)\n",
    "\n",
    "# Save for later\n",
    "pickle.dump(xgboost, open('_'.join(['XGBoost', log.joined_name]), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make extended X2's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X2 = [X2_train_known, X2_train_unknown, X2_valid]\n",
    "\n",
    "# Get X's from sklearn models\n",
    "list_X2_iso_forest = get_values_with_sklearn_models(list_X2, model_dict_iso_forest)\n",
    "list_X2_one_class_svm = get_values_with_sklearn_models(list_X2, model_dict_one_class_svm)\n",
    "\n",
    "# Get X's from xgboost\n",
    "list_X2_xgboost = get_values_with_xgboost(list_X2, xgboost)\n",
    "\n",
    "# Concat\n",
    "#list_L = [L_train_known, L_train_unknown, L_valid]\n",
    "to_concatenate = [list_X2, list_X2_iso_forest, list_X2_one_class_svm, list_X2_xgboost]\n",
    "X2ext_train_known, X2ext_train_unknown, X2ext_valid = get_concatenated(to_concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2Y_train_valid = (X2ext_train_known, X2ext_train_unknown, Y_train_known, Y_train_unknown, X2ext_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_name = 'Ensemble'  # Specify graph class name\n",
    "\n",
    "g_cnfg = Config('graph_02_2nd_layer_for_' + log.joined_name)  # Specify graph configuration name\n",
    "g_cnfg.X_n_features = X2Y_train_valid[0].shape[1]\n",
    "g_cnfg.Y_vector_len = X2Y_train_valid[-1].shape[1]\n",
    "\n",
    "g_cnfg.flat_hiddens = [36, 36]\n",
    "\n",
    "g_cnfg.lr_initial = 0.0001\n",
    "g_cnfg.lr_decay_steps = 100000000\n",
    "g_cnfg.lr_decay_rate = 1.0  # 1.0 means no decay\n",
    "\n",
    "t_cnfg = Config('run_01')  # Specify train configuration name\n",
    "t_cnfg.ckp_dir = 'checkpoints'\n",
    "t_cnfg.tb_dir = 'tensorboard'\n",
    "t_cnfg.log_dir = 'logs'\n",
    "t_cnfg.le = train.le\n",
    "t_cnfg.random_pick_unknown = True\n",
    "t_cnfg.max_step = 100000000\n",
    "t_cnfg.batch_size = 150\n",
    "t_cnfg.dropout_keep_prob = 0.5\n",
    "t_cnfg.log_every = int(int(XY_train_valid[0].shape[0] / 11 * 12) / t_cnfg.batch_size / 2)\n",
    "t_cnfg.n_ave_ll_valid = 8\n",
    "t_cnfg.start_step_early_stopping = 100000000\n",
    "t_cnfg.early_stopping_patience =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: graph_02_2nd_layer_for_Ensemble_graph_04_9models_run_01\n",
      "X_n_features: 48\n",
      "Y_vector_len: 12\n",
      "flat_hiddens: [36, 36]\n",
      "lr_decay_rate: 1.0\n",
      "lr_decay_steps: 100,000,000\n",
      "lr_initial: 0.0001\n",
      "\n",
      "name: run_01\n",
      "batch_size: 150\n",
      "ckp_dir: checkpoints\n",
      "dropout_keep_prob: 0.5\n",
      "early_stopping_patience: 0.1\n",
      "le: LabelEncoder()\n",
      "log_dir: logs\n",
      "log_every: 79\n",
      "max_step: 100,000,000\n",
      "n_ave_ll_valid: 8\n",
      "random_pick_unknown: 1\n",
      "start_step_early_stopping: 100,000,000\n",
      "tb_dir: tensorboard\n",
      "\n",
      "============================================================\n",
      "Ensemble_graph_02_2nd_layer_for_Ensemble_graph_04_9models_run_01_run_01\n",
      "============================================================\n",
      "Epoch size is 23,815 | Batch size is 150 | 158 steps per epoch\n",
      "115 leftover gets discarded at the end of every epoch\n",
      "\n",
      "Training starts @ 01/16/2018 01:11:41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8891315b8d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mGraphClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_cnfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_cnfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2Y_train_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/ssd120g/kumiko/ML/speech-recognition/kaggle_speech_recog/graphs/useful_tf_graph.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, cnfg, XY_train_valid, annotate)\u001b[0m\n\u001b[1;32m     79\u001b[0m                                            feed_dict={self.X: X_batch, self.Y: Y_batch, \n\u001b[1;32m     80\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                                                       self.is_training: True})\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcnfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Keep track of training progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(g_cnfg)\n",
    "print(t_cnfg)\n",
    "\n",
    "GraphClass = globals()[graph_name]\n",
    "graph = GraphClass(g_cnfg)\n",
    "graph.train_model(t_cnfg, X2Y_train_valid, annotate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
