{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from kaggle_speech_recog import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature and label matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPPED train/audio/_background_noise_/README.md File format b'# Ba'... not understood.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/librosa/filters.py:261: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    }
   ],
   "source": [
    "X_vector_len = 16000\n",
    "train = SpeechList.get_train('train/audio')\n",
    "XY_train_valid = train.get_group_unknown_spectrogram_X_and_Y(X_vector_len=X_vector_len, spec_v='3', take_log=False, \n",
    "                                                             split_noise=True, n_fabricate_noise=1600, \n",
    "                                                             split=0.85)\n",
    "\n",
    "# XY_train_valid = (X_train_known, X_train_unknown, Y_train_known, Y_train_unknown, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get logits from trained neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2log = 'logs/Ensemble_graph_04_9models_run_01.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_03_lr_decay_run_01_group_unknown/best/model-57354\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/NoveltyDetectionSpectrogramMultiLSTMRandomInputModify_graph_01_run_01/best/model-82750\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_02_run_01/best/model-90650\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify2_graph_02_lower_lr_lr_decay_run_01_group_unknown/best/model-53088\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramCLSTMBidirectional_graph_03_run_01/best/model-17450\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramDSConvDropout_graph_01_run_01/best/model-22740\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM2_graph_01_run_01_group_unknown/best/model-23858\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_03_conv3x3_lower_lr_run_01_group_unknown/best/model-142358\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_04_conv5x1_lower_lr_run_01_group_unknown/best/model-229416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_03_lr_decay_run_01_group_unknown/best/model-57354\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/NoveltyDetectionSpectrogramMultiLSTMRandomInputModify_graph_01_run_01/best/model-82750\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_02_run_01/best/model-90650\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify2_graph_02_lower_lr_lr_decay_run_01_group_unknown/best/model-53088\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramCLSTMBidirectional_graph_03_run_01/best/model-17450\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramDSConvDropout_graph_01_run_01/best/model-22740\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM2_graph_01_run_01_group_unknown/best/model-23858\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_03_conv3x3_lower_lr_run_01_group_unknown/best/model-142358\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_04_conv5x1_lower_lr_run_01_group_unknown/best/model-229416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_03_lr_decay_run_01_group_unknown/best/model-57354\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/NoveltyDetectionSpectrogramMultiLSTMRandomInputModify_graph_01_run_01/best/model-82750\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify_graph_02_run_01/best/model-90650\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramMultiLSTMRandomInputModify2_graph_02_lower_lr_lr_decay_run_01_group_unknown/best/model-53088\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramCLSTMBidirectional_graph_03_run_01/best/model-17450\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramDSConvDropout_graph_01_run_01/best/model-22740\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM2_graph_01_run_01_group_unknown/best/model-23858\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_03_conv3x3_lower_lr_run_01_group_unknown/best/model-142358\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SpectrogramConcatCLSTM_graph_04_conv5x1_lower_lr_run_01_group_unknown/best/model-229416\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/Ensemble_graph_04_9models_run_01/best/model-110679\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/Ensemble_graph_04_9models_run_01/best/model-110679\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/Ensemble_graph_04_9models_run_01/best/model-110679\n"
     ]
    }
   ],
   "source": [
    "X_train_known, X_train_unknown, Y_train_known, Y_train_unknown, X_valid, Y_valid = XY_train_valid\n",
    "log = pickle.load(open(path2log, 'rb'))\n",
    "\n",
    "if hasattr(log.t_cnfg, 'ensemble_logs'):\n",
    "    L_train_known = gather_logits(X_train_known, log_dir='logs', logs=log.t_cnfg.ensemble_logs)\n",
    "    L_train_unknown = gather_logits(X_train_unknown, log_dir='logs', logs=log.t_cnfg.ensemble_logs)\n",
    "    L_valid = gather_logits(X_valid, log_dir='logs', logs=log.t_cnfg.ensemble_logs)\n",
    "    \n",
    "GraphClass = globals()[log.graph_name]  # Pick up graph class used to train model\n",
    "graph = GraphClass(log.g_cnfg)  # Load the same graph configuration\n",
    "\n",
    "if hasattr(log.t_cnfg, 'ensemble_logs'):\n",
    "    X2_train_known = graph.get_logits(L_train_known, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)  # Use best model in checkpoint directory\n",
    "    X2_train_unknown = graph.get_logits(L_train_unknown, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "    X2_valid = graph.get_logits(L_valid, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "else:\n",
    "    X2_train_known = graph.get_logits(X_train_known, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "    X2_train_unknown = graph.get_logits(X_train_unknown, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)\n",
    "    X2_valid = graph.get_logits(X_valid, ckp_dir=log.ckp_dir, batch_size=log.t_cnfg.batch_size, annotate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train IsolationForest and OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = np.concatenate((X2_train_known, X2_train_unknown, X2_valid), axis=0)\n",
    "Y = np.concatenate((Y_train_known, Y_train_unknown, Y_valid), axis=0)\n",
    "Y_argmax = np.argmax(Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict_iso_forest = {}\n",
    "model_dict_one_class_svm = {}\n",
    "\n",
    "iso_forest_contamination = 0.005\n",
    "one_class_svm_nu = 0.01\n",
    "\n",
    "for i in list(set(Y_argmax)):  # [0: # of labels]\n",
    "    i_X2 = X2[np.where(Y_argmax == i)[0], :]\n",
    "    \n",
    "    model_dict_iso_forest[i] = IsolationForest(max_samples=len(i_X2), contamination=iso_forest_contamination).fit(i_X2)\n",
    "    model_dict_one_class_svm[i] = OneClassSVM(nu=one_class_svm_nu).fit(i_X2)\n",
    "\n",
    "# Save for later\n",
    "pickle.dump(model_dict_iso_forest, open('_'.join(['IsolationForests', log.joined_name]), 'wb'))\n",
    "pickle.dump(model_dict_one_class_svm, open('_'.join(['OneClassSVMs', log.joined_name]), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_pick_unknown = True\n",
    "\n",
    "if random_pick_unknown:\n",
    "    i_train_unknown = np.random.choice(len(X2_train_unknown), size=int(len(X2_train_known) / 11), replace=False)\n",
    "    random_X2_train_unknown = X2_train_unknown[i_train_unknown, :]\n",
    "    random_Y_train_unknown = Y_train_unknown[i_train_unknown, :]\n",
    "\n",
    "    X2_train = np.concatenate((X2_train_known, random_X2_train_unknown))\n",
    "    Y_train = np.concatenate((Y_train_known, random_Y_train_unknown))\n",
    "else:\n",
    "    X2_train = np.concatenate((X2_train_known, X2_train_unknown))\n",
    "    Y_train = np.concatenate((Y_train_known, Y_train_unknown))\n",
    "    \n",
    "Y_train_argmax = np.argmax(Y_train, axis=1)\n",
    "Y_valid_argmax = np.argmax(Y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.19606\tvalid-mlogloss:2.1977\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:1.04039\tvalid-mlogloss:1.04899\n",
      "[20]\ttrain-mlogloss:0.602883\tvalid-mlogloss:0.614416\n",
      "[30]\ttrain-mlogloss:0.368962\tvalid-mlogloss:0.382114\n",
      "[40]\ttrain-mlogloss:0.233263\tvalid-mlogloss:0.247542\n",
      "[50]\ttrain-mlogloss:0.152353\tvalid-mlogloss:0.167321\n",
      "[60]\ttrain-mlogloss:0.103168\tvalid-mlogloss:0.118707\n",
      "[70]\ttrain-mlogloss:0.072966\tvalid-mlogloss:0.088884\n",
      "[80]\ttrain-mlogloss:0.054192\tvalid-mlogloss:0.070413\n",
      "[90]\ttrain-mlogloss:0.042259\tvalid-mlogloss:0.058714\n",
      "[100]\ttrain-mlogloss:0.034524\tvalid-mlogloss:0.051283\n",
      "[110]\ttrain-mlogloss:0.02934\tvalid-mlogloss:0.046375\n",
      "[120]\ttrain-mlogloss:0.025753\tvalid-mlogloss:0.042951\n",
      "[130]\ttrain-mlogloss:0.023213\tvalid-mlogloss:0.040573\n",
      "[140]\ttrain-mlogloss:0.021377\tvalid-mlogloss:0.038952\n",
      "[150]\ttrain-mlogloss:0.020035\tvalid-mlogloss:0.038004\n",
      "[160]\ttrain-mlogloss:0.018966\tvalid-mlogloss:0.037158\n",
      "[170]\ttrain-mlogloss:0.018091\tvalid-mlogloss:0.03683\n",
      "[180]\ttrain-mlogloss:0.017389\tvalid-mlogloss:0.036461\n",
      "[190]\ttrain-mlogloss:0.016761\tvalid-mlogloss:0.036272\n",
      "[200]\ttrain-mlogloss:0.016222\tvalid-mlogloss:0.036116\n",
      "[210]\ttrain-mlogloss:0.015752\tvalid-mlogloss:0.036071\n",
      "[220]\ttrain-mlogloss:0.015291\tvalid-mlogloss:0.03601\n",
      "[230]\ttrain-mlogloss:0.014921\tvalid-mlogloss:0.035956\n",
      "[240]\ttrain-mlogloss:0.014545\tvalid-mlogloss:0.03608\n",
      "[250]\ttrain-mlogloss:0.014204\tvalid-mlogloss:0.036223\n",
      "[260]\ttrain-mlogloss:0.013885\tvalid-mlogloss:0.036219\n",
      "[270]\ttrain-mlogloss:0.013592\tvalid-mlogloss:0.036242\n",
      "Stopping. Best iteration:\n",
      "[229]\ttrain-mlogloss:0.014961\tvalid-mlogloss:0.035937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_train = xgb.DMatrix(X2_train, label=Y_train_argmax)\n",
    "xgb_valid = xgb.DMatrix(X2_valid, label=Y_valid_argmax)\n",
    "\n",
    "params = {'objective': 'multi:softprob',  # labels are 1-dim, not one-hot encoded\n",
    "          'num_class': Y_train.shape[-1],\n",
    "          'eval_metric': 'mlogloss', \n",
    "          'eta': 0.05,\n",
    "          'subsample': 0.5,\n",
    "          'max_depth': 1}\n",
    "watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "\n",
    "xgboost = xgb.train(params, xgb_train, num_boost_round=1000, evals=watchlist, \n",
    "                    early_stopping_rounds=50, verbose_eval=10)\n",
    "\n",
    "# Save for later\n",
    "pickle.dump(xgboost, open('_'.join(['XGBoost', log.joined_name]), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make extended X2's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X2 = [X2_train_known, X2_train_unknown, X2_valid]\n",
    "\n",
    "# Get X's from sklearn models\n",
    "list_X2_iso_forest = get_values_with_sklearn_models(list_X2, model_dict_iso_forest)\n",
    "list_X2_one_class_svm = get_values_with_sklearn_models(list_X2, model_dict_one_class_svm)\n",
    "\n",
    "# Get X's from xgboost\n",
    "list_X2_xgboost = get_values_with_xgboost(list_X2, xgboost)\n",
    "\n",
    "# Concat L and 3 additional sets of features\n",
    "list_L = [L_train_known, L_train_unknown, L_valid]\n",
    "to_concatenate = [list_L, list_X2_iso_forest, list_X2_one_class_svm, list_X2_xgboost]\n",
    "X2ext_train_known, X2ext_train_unknown, X2ext_valid = get_concatenated(to_concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2Y_train_valid = (X2ext_train_known, X2ext_train_unknown, Y_train_known, Y_train_unknown, X2ext_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_name = 'Ensemble'  # Specify graph class name\n",
    "\n",
    "g_cnfg = Config('graph_2nd_layer_for_' + log.joined_name)  # Specify graph configuration name\n",
    "g_cnfg.X_n_features = X2Y_train_valid[0].shape[1]\n",
    "g_cnfg.Y_vector_len = X2Y_train_valid[-1].shape[1]\n",
    "\n",
    "g_cnfg.flat_hiddens = [256, 256]\n",
    "\n",
    "g_cnfg.lr_initial = 0.0001\n",
    "g_cnfg.lr_decay_steps = 100000000\n",
    "g_cnfg.lr_decay_rate = 1.0  # 1.0 means no decay\n",
    "\n",
    "t_cnfg = Config('run_01')  # Specify train configuration name\n",
    "t_cnfg.ckp_dir = 'checkpoints'\n",
    "t_cnfg.tb_dir = 'tensorboard'\n",
    "t_cnfg.log_dir = 'logs'\n",
    "t_cnfg.le = train.le\n",
    "t_cnfg.random_pick_unknown = True\n",
    "t_cnfg.max_step = 100000000\n",
    "t_cnfg.batch_size = 150\n",
    "t_cnfg.dropout_keep_prob = 0.5\n",
    "t_cnfg.log_every = int(int(XY_train_valid[0].shape[0] / 11 * 12) / t_cnfg.batch_size / 2)\n",
    "t_cnfg.n_ave_ll_valid = 8\n",
    "t_cnfg.start_step_early_stopping = 100000000\n",
    "t_cnfg.early_stopping_patience =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: graph_2nd_layer_for_Ensemble_graph_04_9models_run_01\n",
      "X_n_features: 190\n",
      "Y_vector_len: 12\n",
      "flat_hiddens: [256, 256]\n",
      "lr_decay_rate: 1.0\n",
      "lr_decay_steps: 100,000,000\n",
      "lr_initial: 0.0001\n",
      "\n",
      "name: run_01\n",
      "batch_size: 150\n",
      "ckp_dir: checkpoints\n",
      "dropout_keep_prob: 0.5\n",
      "early_stopping_patience: 0.1\n",
      "le: LabelEncoder()\n",
      "log_dir: logs\n",
      "log_every: 79\n",
      "max_step: 100,000,000\n",
      "n_ave_ll_valid: 8\n",
      "random_pick_unknown: 1\n",
      "start_step_early_stopping: 100,000,000\n",
      "tb_dir: tensorboard\n",
      "\n",
      "============================================================\n",
      "Ensemble_graph_2nd_layer_for_Ensemble_graph_04_9models_run_01_run_01\n",
      "============================================================\n",
      "Epoch size is 23,815 | Batch size is 150 | 158 steps per epoch\n",
      "115 leftover gets discarded at the end of every epoch\n",
      "\n",
      "Training starts @ 01/15/2018 23:28:38\n"
     ]
    }
   ],
   "source": [
    "print(g_cnfg)\n",
    "print(t_cnfg)\n",
    "\n",
    "GraphClass = globals()[graph_name]\n",
    "graph = GraphClass(g_cnfg)\n",
    "graph.train_model(t_cnfg, X2Y_train_valid, annotate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
